{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code found from http://www.davidsbatista.net/blog/2018/02/23/model_optimization/\n",
    "class EstimatorSelectionHelper:\n",
    "\n",
    "    def __init__(self, models, params):\n",
    "        if not set(models.keys()).issubset(set(params.keys())):\n",
    "            missing_params = list(set(models.keys()) - set(params.keys()))\n",
    "            raise ValueError(\"Some estimators are missing parameters: %s\" % missing_params)\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.keys = models.keys()\n",
    "        self.grid_searches = {}\n",
    "\n",
    "    def fit(self, X, y, cv=3, n_jobs=-1, verbose=1, scoring=None, refit=False):\n",
    "        for key in self.keys:\n",
    "            print(\"Running GridSearchCV for %s.\" % key)\n",
    "            model = self.models[key]\n",
    "            params = self.params[key]\n",
    "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs,\n",
    "                              verbose=verbose, scoring=scoring, refit=refit,\n",
    "                              return_train_score=True)\n",
    "            gs.fit(X,y)\n",
    "            self.grid_searches[key] = gs    \n",
    "\n",
    "    def score_summary(self, sort_by='mean_score'):\n",
    "        def row(key, scores, params):\n",
    "            d = {\n",
    "                 'estimator': key,\n",
    "                 'min_score': min(scores),\n",
    "                 'max_score': max(scores),\n",
    "                 'mean_score': np.mean(scores),\n",
    "                 'std_score': np.std(scores),\n",
    "            }\n",
    "            return pd.Series({**params,**d})\n",
    "\n",
    "        rows = []\n",
    "        for k in self.grid_searches:\n",
    "            print(k)\n",
    "            params = self.grid_searches[k].cv_results_['params']\n",
    "            scores = []\n",
    "            for i in range(self.grid_searches[k].cv):\n",
    "                key = \"split{}_test_score\".format(i)\n",
    "                r = self.grid_searches[k].cv_results_[key]        \n",
    "                scores.append(r.reshape(len(params),1))\n",
    "\n",
    "            all_scores = np.hstack(scores)\n",
    "            for p, s in zip(params,all_scores):\n",
    "                rows.append((row(k, s, p)))\n",
    "\n",
    "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
    "\n",
    "        columns = ['estimator', 'min_score', 'mean_score', 'max_score', 'std_score']\n",
    "        columns = columns + [c for c in df.columns if c not in columns]\n",
    "\n",
    "        return df[columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model_params = {\n",
    "    'LogisticRegression' : {\n",
    "        'penalty' : ['l1', 'l2'],\n",
    "        'C' : np.arange(.05, 1, .05) },\n",
    "    'KNN' : {\n",
    "        'n_neighbors' : np.arange(3, 22, 2) },\n",
    "    'NaiveBayes' : {\n",
    "        'alpha' : np.arange(.05, 2, .05)},\n",
    "    'DecisionTree': {\n",
    "        'max_depth' : [None, 6, 10, 14], \n",
    "        'min_samples_leaf' : [1, 2],\n",
    "        'min_samples_split': [2, 3] },\n",
    "    'BaggedDecisionTree' : {\n",
    "        'n_estimators' : [20, 60, 100] },\n",
    "    'RandomForest' : {\n",
    "        'n_estimators' : [20, 60, 100],\n",
    "        'max_depth' : [None, 2, 6, 10],\n",
    "        'min_samples_split' : [2, 3, 4] },\n",
    "    'ExtraTrees' : {\n",
    "        'n_estimators' : [20, 60, 100],\n",
    "        'max_depth' : [None, 6, 10, 14],\n",
    "        'min_samples_leaf' : [1, 2], \n",
    "        'min_samples_split' : [2, 3], },\n",
    "    'AdaBoost' : {\n",
    "        'n_estimators' : np.arange(100, 151, 25),\n",
    "        'learning_rate' : np.linspace(0.05, 1, 10) },\n",
    "    'GradientBoosting' : {\n",
    "        'n_estimators' : np.arange(5, 150, 15),\n",
    "        'learning_rate' : np.linspace(0.05, 1, 10),\n",
    "        'max_depth' : [1, 2, 3] },\n",
    "    'SVM' : {\n",
    "        'C' : np.arange(0.05, 1, .05),\n",
    "        'kernel' : ['rbf', 'linear'] },\n",
    "     'XGBoost' : {\n",
    "        'n_estimators'  : np.arange(100, 151, 25), \n",
    "        'learning_rate' : np.arange(0.1, 1, .3),\n",
    "        'max_depth' : [3],\n",
    "        'alpha' : np.arange(0, 1, .3),\n",
    "        'lambda' : np.arange(0, 1, .3),\n",
    "        'gamma' : np.arange(0, 1, .3),\n",
    "        'subsample' : [.5],\n",
    "        'n_jobs' : [4],}\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chang\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "sm = SMOTE(sampling_strategy=1,random_state=666)\n",
    "\n",
    "train = pd.read_csv('./data/train_weather.csv')\n",
    "train_dummies = pd.get_dummies(train,drop_first=True,columns=['Species','Street'])\n",
    "y = train_dummies['WnvPresent']\n",
    "X = train_dummies[[col for col in train_dummies.columns if col != 'WnvPresent']]\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(X,y,test_size = 0.3, random_state = 666)\n",
    "sampledX,sampledy = sm.fit_sample(train_x,train_y)\n",
    "sampledX=scaler.fit_transform(sampledX)\n",
    "test_x=scaler.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_models = {\n",
    "#     'LogisticRegression' : /LogisticRegression(random_state = 42),\n",
    "#     'KNN': KNeighborsClassifier(), \n",
    "# #     'NaiveBayes' : MultinomialNB(), #does not work with negative vals\n",
    "#     'DecisionTree' : DecisionTreeClassifier(random_state = 42), \n",
    "#     'BaggedDecisionTree' : BaggingClassifier(random_state = 42),\n",
    "#     'RandomForest' : RandomForestClassifier(random_state = 42), \n",
    "#     'ExtraTrees' : ExtraTreesClassifier(random_state = 42), \n",
    "#     'AdaBoost' : AdaBoostClassifier(random_state=42), \n",
    "    'GradientBoosting' : GradientBoostingClassifier(random_state = 42),\n",
    "#     'SVM' : SVC(random_state=42),\n",
    "#     'XGBoost' : XGBClassifier(random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for GradientBoosting.\n",
      "Fitting 3 folds for each of 300 candidates, totalling 900 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:   30.0s\n",
      "[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:  9.6min\n",
      "[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed: 17.1min\n",
      "[Parallel(n_jobs=3)]: Done 900 out of 900 | elapsed: 19.7min finished\n"
     ]
    }
   ],
   "source": [
    "search = EstimatorSelectionHelper(classifier_models, classifier_model_params)\n",
    "search.fit(sampledX,sampledy, scoring='recall', n_jobs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then score our different models and output our results to a csv for archival."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoosting\n"
     ]
    }
   ],
   "source": [
    "score2=search.score_summary(sort_by='max_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "score1=pd.read_csv(r'.\\data\\score2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chang\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "score1=pd.concat([score1,score2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "score1.to_csv(r'.\\data\\score3.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>alpha</th>\n",
       "      <th>estimator</th>\n",
       "      <th>gamma</th>\n",
       "      <th>kernel</th>\n",
       "      <th>lambda</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>max_score</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>min_score</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>n_jobs</th>\n",
       "      <th>n_neighbors</th>\n",
       "      <th>penalty</th>\n",
       "      <th>std_score</th>\n",
       "      <th>subsample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ExtraTrees</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.991387</td>\n",
       "      <td>0.984927</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.972868</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00853394</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BaggedDecisionTree</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.991387</td>\n",
       "      <td>0.957221</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.894057</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0447135</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ExtraTrees</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.991387</td>\n",
       "      <td>0.984927</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.972868</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00853394</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.986219</td>\n",
       "      <td>0.971433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.945306</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.018528</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>0.985788</td>\n",
       "      <td>0.959231</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.921189</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0275946</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KNN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.955642</td>\n",
       "      <td>0.942578</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.920758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0155291</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.855154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.00379266</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.860034</td>\n",
       "      <td>0.855154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.850991</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.00372689</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.788889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.964255</td>\n",
       "      <td>0.931668</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.867356</td>\n",
       "      <td>150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0454771</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SVM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rbf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.94186</td>\n",
       "      <td>0.923629</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.890612</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0233892</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.988372</td>\n",
       "      <td>0.951766</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.879845</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0508584</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.988372</td>\n",
       "      <td>0.951766</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.879845</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0508584</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.988372</td>\n",
       "      <td>0.951766</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.879845</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0508584</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.988372</td>\n",
       "      <td>0.951766</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.879845</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0508584</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.988372</td>\n",
       "      <td>0.951766</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.879845</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0508584</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.988372</td>\n",
       "      <td>0.951766</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.879845</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0508584</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.988372</td>\n",
       "      <td>0.951766</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.879845</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0508584</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.988372</td>\n",
       "      <td>0.951766</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.879845</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0508584</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.988372</td>\n",
       "      <td>0.951766</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.879845</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0508584</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.988372</td>\n",
       "      <td>0.951766</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.879845</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0508584</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.988372</td>\n",
       "      <td>0.951766</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.879845</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0508584</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.988372</td>\n",
       "      <td>0.951766</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.879845</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0508584</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.988372</td>\n",
       "      <td>0.951766</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.879845</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0508584</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.988372</td>\n",
       "      <td>0.951766</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.879845</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0508584</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.988372</td>\n",
       "      <td>0.951766</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.879845</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0508584</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.988372</td>\n",
       "      <td>0.951766</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.879845</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0508584</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.261111</td>\n",
       "      <td>3</td>\n",
       "      <td>0.98708</td>\n",
       "      <td>0.949038</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.875538</td>\n",
       "      <td>140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.051983</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        C alpha           estimator gamma kernel lambda learning_rate  \\\n",
       "13    NaN   NaN          ExtraTrees   NaN    NaN    NaN           NaN   \n",
       "14    NaN   NaN  BaggedDecisionTree   NaN    NaN    NaN           NaN   \n",
       "15    NaN   NaN          ExtraTrees   NaN    NaN    NaN           NaN   \n",
       "25    NaN   NaN        RandomForest   NaN    NaN    NaN           NaN   \n",
       "28    NaN   NaN        DecisionTree   NaN    NaN    NaN           NaN   \n",
       "64    NaN   NaN                 KNN   NaN    NaN    NaN           NaN   \n",
       "135  0.15   NaN  LogisticRegression   NaN    NaN    NaN           NaN   \n",
       "142  0.05   NaN  LogisticRegression   NaN    NaN    NaN           NaN   \n",
       "153   NaN   NaN            AdaBoost   NaN    NaN    NaN      0.788889   \n",
       "172  0.90   NaN                 SVM   NaN    rbf    NaN           NaN   \n",
       "500   NaN   0.9             XGBoost   0.3    NaN    0.9           0.4   \n",
       "212   NaN   0.3             XGBoost   0.3    NaN    0.9           0.4   \n",
       "473   NaN   0.9             XGBoost   0.3    NaN      0           0.4   \n",
       "329   NaN   0.6             XGBoost   0.3    NaN      0           0.4   \n",
       "338   NaN   0.6             XGBoost   0.3    NaN    0.3           0.4   \n",
       "491   NaN   0.9             XGBoost   0.3    NaN    0.6           0.4   \n",
       "482   NaN   0.9             XGBoost   0.3    NaN    0.3           0.4   \n",
       "347   NaN   0.6             XGBoost   0.3    NaN    0.6           0.4   \n",
       "68    NaN     0             XGBoost   0.3    NaN    0.9           0.4   \n",
       "194   NaN   0.3             XGBoost   0.3    NaN    0.3           0.4   \n",
       "50    NaN     0             XGBoost   0.3    NaN    0.3           0.4   \n",
       "185   NaN   0.3             XGBoost   0.3    NaN      0           0.4   \n",
       "203   NaN   0.3             XGBoost   0.3    NaN    0.6           0.4   \n",
       "356   NaN   0.6             XGBoost   0.3    NaN    0.9           0.4   \n",
       "41    NaN     0             XGBoost   0.3    NaN      0           0.4   \n",
       "59    NaN     0             XGBoost   0.3    NaN    0.6           0.4   \n",
       "89    NaN   NaN    GradientBoosting   NaN    NaN    NaN      0.261111   \n",
       "\n",
       "    max_depth max_score mean_score  min_samples_leaf  min_samples_split  \\\n",
       "13        NaN  0.991387   0.984927               2.0                2.0   \n",
       "14        NaN  0.991387   0.957221               NaN                NaN   \n",
       "15        NaN  0.991387   0.984927               2.0                3.0   \n",
       "25         10  0.986219   0.971433               NaN                3.0   \n",
       "28         14  0.985788   0.959231               1.0                2.0   \n",
       "64        NaN  0.955642   0.942578               NaN                NaN   \n",
       "135       NaN  0.860465   0.855154               NaN                NaN   \n",
       "142       NaN  0.860034   0.855154               NaN                NaN   \n",
       "153       NaN  0.964255   0.931668               NaN                NaN   \n",
       "172       NaN   0.94186   0.923629               NaN                NaN   \n",
       "500         3  0.988372   0.951766               NaN                NaN   \n",
       "212         3  0.988372   0.951766               NaN                NaN   \n",
       "473         3  0.988372   0.951766               NaN                NaN   \n",
       "329         3  0.988372   0.951766               NaN                NaN   \n",
       "338         3  0.988372   0.951766               NaN                NaN   \n",
       "491         3  0.988372   0.951766               NaN                NaN   \n",
       "482         3  0.988372   0.951766               NaN                NaN   \n",
       "347         3  0.988372   0.951766               NaN                NaN   \n",
       "68          3  0.988372   0.951766               NaN                NaN   \n",
       "194         3  0.988372   0.951766               NaN                NaN   \n",
       "50          3  0.988372   0.951766               NaN                NaN   \n",
       "185         3  0.988372   0.951766               NaN                NaN   \n",
       "203         3  0.988372   0.951766               NaN                NaN   \n",
       "356         3  0.988372   0.951766               NaN                NaN   \n",
       "41          3  0.988372   0.951766               NaN                NaN   \n",
       "59          3  0.988372   0.951766               NaN                NaN   \n",
       "89          3   0.98708   0.949038               NaN                NaN   \n",
       "\n",
       "    min_score n_estimators n_jobs  n_neighbors penalty   std_score subsample  \n",
       "13   0.972868           60    NaN          NaN     NaN  0.00853394       NaN  \n",
       "14   0.894057          100    NaN          NaN     NaN   0.0447135       NaN  \n",
       "15   0.972868           60    NaN          NaN     NaN  0.00853394       NaN  \n",
       "25   0.945306          100    NaN          NaN     NaN    0.018528       NaN  \n",
       "28   0.921189          NaN    NaN          NaN     NaN   0.0275946       NaN  \n",
       "64   0.920758          NaN    NaN          3.0     NaN   0.0155291       NaN  \n",
       "135  0.851852          NaN    NaN          NaN      l2  0.00379266       NaN  \n",
       "142  0.850991          NaN    NaN          NaN      l2  0.00372689       NaN  \n",
       "153  0.867356          150    NaN          NaN     NaN   0.0454771       NaN  \n",
       "172  0.890612          NaN    NaN          NaN     NaN   0.0233892       NaN  \n",
       "500  0.879845          150      4          NaN     NaN   0.0508584       0.5  \n",
       "212  0.879845          150      4          NaN     NaN   0.0508584       0.5  \n",
       "473  0.879845          150      4          NaN     NaN   0.0508584       0.5  \n",
       "329  0.879845          150      4          NaN     NaN   0.0508584       0.5  \n",
       "338  0.879845          150      4          NaN     NaN   0.0508584       0.5  \n",
       "491  0.879845          150      4          NaN     NaN   0.0508584       0.5  \n",
       "482  0.879845          150      4          NaN     NaN   0.0508584       0.5  \n",
       "347  0.879845          150      4          NaN     NaN   0.0508584       0.5  \n",
       "68   0.879845          150      4          NaN     NaN   0.0508584       0.5  \n",
       "194  0.879845          150      4          NaN     NaN   0.0508584       0.5  \n",
       "50   0.879845          150      4          NaN     NaN   0.0508584       0.5  \n",
       "185  0.879845          150      4          NaN     NaN   0.0508584       0.5  \n",
       "203  0.879845          150      4          NaN     NaN   0.0508584       0.5  \n",
       "356  0.879845          150      4          NaN     NaN   0.0508584       0.5  \n",
       "41   0.879845          150      4          NaN     NaN   0.0508584       0.5  \n",
       "59   0.879845          150      4          NaN     NaN   0.0508584       0.5  \n",
       "89   0.875538          140    NaN          NaN     NaN    0.051983       NaN  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score1[score1['mean_score'] == score1.groupby('estimator')['mean_score'].transform('max')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
