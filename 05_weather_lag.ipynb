{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use function *multi_merge(train,test,list_of_lag_days,list_of_feature_lists)* to create variations of our datasets.\n",
    "\n",
    "---\n",
    "\n",
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import haversine as hv\n",
    "from datetime import timedelta\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set station coordinates\n",
    "STATIONS = {\n",
    "    1 : (41.995,-87.933),\n",
    "    2 : (41.786,-87.752)\n",
    "}\n",
    "\n",
    "def nearest_station(in_coords):\n",
    "    \n",
    "    dist = {k:hv.haversine(in_coords,v) for k,v in STATIONS.items()}\n",
    "    \n",
    "    return min(dist, key=dist.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import train,test data and map nearest weather station\n",
    "train = pd.read_csv(r'.\\data\\train.csv')\n",
    "test = pd.read_csv(r'.\\data\\test.csv')\n",
    "train['nearest_station'] = train.apply(lambda x: nearest_station([x.Latitude, x.Longitude]), axis=1)\n",
    "test['nearest_station'] = test.apply(lambda x: nearest_station([x.Latitude, x.Longitude]), axis=1)\n",
    "train.Date = train.Date.astype('datetime64[ns]')\n",
    "test.Date = test.Date.astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import weather data and convert date type\n",
    "weather = pd.read_csv(r'.\\data\\weather_cleaned_stack_back.csv')\n",
    "weather.drop(columns='Unnamed: 0',inplace=True)\n",
    "weather.Date = weather.Date.astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Address', 'Species', 'Block', 'Street', 'Trap',\n",
       "       'AddressNumberAndStreet', 'Latitude', 'Longitude', 'AddressAccuracy',\n",
       "       'NumMosquitos', 'WnvPresent', 'nearest_station'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Munging weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_list=['Tmax','Tmin','Tavg','Depart','DewPoint','WetBulb','Cool']\n",
    "rain_list=['PrecipTotal']\n",
    "day_list=['Sunset','DaylightHrs','StnPressure','SeaLevel','ResultSpeed',\n",
    "          'ResultDir','AvgSpeed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to merge weather features based on date lag\n",
    "def to_merge(train,test,lag,feature_list):\n",
    "    train['date_lag'] = train.Date.map(lambda x : x - timedelta(days=lag))\n",
    "    test['date_lag'] = test.Date.map(lambda x : x - timedelta(days=lag))\n",
    "    feature_list=feature_list+['Date','Station']\n",
    "    train_weather = train.merge(weather[feature_list],left_on=['date_lag','nearest_station'],right_on=['Date','Station'])\n",
    "    test_weather = test.merge(weather[feature_list],left_on=['date_lag','nearest_station'],right_on=['Date','Station'])\n",
    "    train_weather.drop(['Date_y','Station'],axis=1,inplace=True)\n",
    "    train_weather.rename({'Date_x':'Date'},axis=1,inplace=True)\n",
    "    test_weather.drop(['Date_y','Station'],axis=1,inplace=True)\n",
    "    test_weather.rename({'Date_x':'Date'},axis=1,inplace=True)\n",
    "    return(train_weather,test_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to merge multiple weather features with different date lags\n",
    "def multi_merge(train,test,lag_list,list_of_lists):\n",
    "    if len(lag_list)!=len(list_of_lists):\n",
    "        print('Mismatch in list lengths')\n",
    "        return None\n",
    "    else:\n",
    "        for i in range(len(lag_list)):\n",
    "            train,test=to_merge(train,test,lag_list[i],list_of_lists[i])\n",
    "        train['month'] = train.Date.map(lambda x : x.month)\n",
    "        test['month'] = test.Date.map(lambda x : x.month)\n",
    "        return(train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_list=[0,3,11]\n",
    "feat_list=[day_list,temp_list,rain_list]\n",
    "train_1,test_1=multi_merge(train,test,lag_list,feat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['month','Species','NumMosquitos','Sunset', 'Street',\n",
    "       'DaylightHrs', 'Tmax', 'Tmin', 'Tavg', 'Depart', 'DewPoint', 'WetBulb',\n",
    "       'Cool', 'PrecipTotal', 'StnPressure', 'SeaLevel', 'ResultSpeed',\n",
    "       'ResultDir', 'AvgSpeed','WnvPresent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1 = train_1[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Preparation of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chang\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\chang\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "C:\\Users\\chang\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "sm = SMOTE(sampling_strategy=1,random_state=666)\n",
    "\n",
    "train_dummies = pd.get_dummies(train_1,drop_first=True,columns=['Species','Street'])\n",
    "y = train_dummies['WnvPresent']\n",
    "X = train_dummies[[col for col in train_dummies.columns if col != 'WnvPresent']]\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(X,y,test_size = 0.3, random_state = 666,stratify=y)\n",
    "train_x=scaler.fit_transform(train_x)\n",
    "test_x=scaler.transform(test_x)\n",
    "sampledX,sampledy = sm.fit_sample(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6484848484848484"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test fit and predict, benchmark\n",
    "lr=LogisticRegression(solver='liblinear')\n",
    "lr.fit(sampledX,sampledy)\n",
    "pred=lr.predict(test_x)\n",
    "recall_score(test_y,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Testing different ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_iter(train,test,lag_list,feature_list):\n",
    "    train_1,test_1=multi_merge(train,test,lag_list,feat_list)\n",
    "    train_1 = train_1[cols]\n",
    "    scaler = StandardScaler()\n",
    "    sm = SMOTE(sampling_strategy=1,random_state=666)\n",
    "\n",
    "    train_dummies = pd.get_dummies(train_1,drop_first=True,columns=['Species','Street'])\n",
    "    train_dummies=train_dummies.astype('float64')\n",
    "    y = train_dummies['WnvPresent']\n",
    "    X = train_dummies[[col for col in train_dummies.columns if col != 'WnvPresent']]\n",
    "\n",
    "    train_x, test_x, train_y, test_y = train_test_split(X,y,test_size = 0.3, random_state = 666,stratify=y)\n",
    "    train_x=scaler.fit_transform(train_x)\n",
    "    test_x=scaler.transform(test_x)\n",
    "    sampledX,sampledy = sm.fit_sample(train_x,train_y)\n",
    "    \n",
    "    lr=LogisticRegression(solver='liblinear')\n",
    "    lr.fit(sampledX,sampledy)\n",
    "    pred=lr.predict(test_x)\n",
    "    return (recall_score(test_y,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp days 1: 0.6606060606060606\n",
      "temp days 2: 0.6606060606060606\n",
      "temp days 3: 0.6484848484848484\n",
      "temp days 4: 0.6666666666666666\n",
      "temp days 5: 0.6424242424242425\n",
      "temp days 6: 0.6606060606060606\n",
      "temp days 7: 0.6424242424242425\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,8):\n",
    "    lag_list=[0,i,11]\n",
    "    print('temp days ' + str(i) + ': ' + str(score_iter(train,test,lag_list,feat_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rain day 1: 0.6666666666666666\n",
      "rain day 2: 0.6666666666666666\n",
      "rain day 3: 0.6606060606060606\n",
      "rain day 4: 0.6666666666666666\n",
      "rain day 5: 0.6484848484848484\n",
      "rain day 6: 0.6545454545454545\n",
      "rain day 7: 0.6606060606060606\n",
      "rain day 8: 0.6666666666666666\n",
      "rain day 9: 0.6606060606060606\n",
      "rain day 10: 0.6666666666666666\n",
      "rain day 11: 0.6666666666666666\n",
      "rain day 12: 0.6666666666666666\n",
      "rain day 13: 0.6606060606060606\n",
      "rain day 14: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "for i in range (1,15):\n",
    "    lag_list=[0,4,i]\n",
    "    print('rain day '+str(i) + ': ' + str(score_iter(train,test,lag_list,feat_list)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
